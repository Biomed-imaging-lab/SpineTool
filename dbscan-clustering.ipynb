{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dfb6e4c",
   "metadata": {},
   "source": [
    "# Dendritic Spine Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973ed74c",
   "metadata": {},
   "source": [
    "Glossary: \n",
    "- Group — a division of spines defined by experiment design, e.g., division of spines into experimental and control groups;\n",
    "- Class — a group of spines that meet specific criteria, e.g., stubby, mushroom, thin and filopodia groupings. In clustering results classes are also called groups, because classification is a variation of spine grouping;\n",
    "- Cluster — a homogenous group of spines in the data based on their morphometric features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab729e8f",
   "metadata": {},
   "source": [
    "1. Set `dataset_path`, `show_reduction_method` and `manual_classfication` (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf6c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spine_metrics import SpineMetricDataset\n",
    "from notebook_widgets import SpineMeshDataset, intersection_ratios_mean_distance, create_dir\n",
    "from spine_segmentation import apply_scale\n",
    "from spine_fitter import SpineGrouping\n",
    "from spine_clusterization import SpineClusterizer, DBSCANSpineClusterizer\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import silhouette_score\n",
    "from typing import Optional\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "dataset_path = \"example dataset\"\n",
    "scale = (1, 1, 1)\n",
    "show_reduction_method = \"tsne\"\n",
    "    \n",
    "# load meshes and apply scale\n",
    "spine_dataset = SpineMeshDataset().load(dataset_path)\n",
    "spine_dataset.apply_scale(scale)\n",
    "\n",
    "# load manual classification or other labeling, comment out lines with the unused file, \n",
    "# or all lines if required \n",
    "manual_classification = SpineGrouping().load(f\"{dataset_path}/manual_classification/manual_classification_merged_reduced.json\")\n",
    "manual_classification = manual_classification.get_spines_subset(spine_dataset.spine_names)\n",
    "# labeling = SpineGrouping().load(f\"{dataset_path}/labeling_by_dirs.json\")\n",
    "# labeling = manual_classification.get_spines_subset(spine_dataset.spine_names)\n",
    "\n",
    "# load metrics\n",
    "spine_metrics = SpineMetricDataset().load(f\"{dataset_path}/metrics.csv\")\n",
    "spine_metrics = spine_metrics.get_spines_subset(manual_classification.samples)\n",
    "\n",
    "# extract metric subsets\n",
    "classic = spine_metrics.get_metrics_subset(['OpenAngle', 'CVD', \"JunctionArea\", 'AverageDistance', 'Length', 'Area', 'Volume', 'ConvexHullVolume', 'ConvexHullRatio', \"LengthVolumeRatio\", \"LengthAreaRatio\"])\n",
    "chord = spine_metrics.get_metrics_subset(['ChordDistribution'])\n",
    "\n",
    "\n",
    "# prepare folders for export\n",
    "create_dir(f\"{dataset_path}/clustering\")\n",
    "classic_save_path = f\"{dataset_path}/clustering/classic\"\n",
    "create_dir(classic_save_path)\n",
    "chord_save_path = f\"{dataset_path}/clustering/chord/euclidean\"\n",
    "create_dir(f\"{dataset_path}/clustering/chord\")\n",
    "create_dir(f\"{dataset_path}/clustering/chord/euclidean\")\n",
    "chord_js_save_path = f\"{dataset_path}/clustering/chord/jensen-shannon\"\n",
    "create_dir(f\"{dataset_path}/clustering/chord/jensen-shannon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8111f856",
   "metadata": {},
   "source": [
    "2. Functions for calculation of elbow score and silhouette metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c4351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan_elbow_score(clusterizer: DBSCANSpineClusterizer) -> float:\n",
    "    # number of points with not enough neighbours close enough to form a cluster\n",
    "    neigh = NearestNeighbors(n_neighbors=clusterizer.min_samples, metric=clusterizer.metric)\n",
    "    data = clusterizer.fit_metrics.as_array()\n",
    "    nbrs = neigh.fit(data)\n",
    "    distances, indices = nbrs.kneighbors(data)\n",
    "    # get distances to closest k-th neighbour\n",
    "    distances = distances[:, -1]\n",
    "    # sort distances in descending order\n",
    "    distances = -np.sort(-distances, axis=0)\n",
    "    for i in range(len(distances)):\n",
    "        if clusterizer.eps > distances[i]:\n",
    "            return i\n",
    "    return len(distances)\n",
    "\n",
    "def silhouette(clusterizer: SpineClusterizer, metric: Optional[callable] = None) -> float:\n",
    "    datas = []\n",
    "    labels = []\n",
    "    for i, group in enumerate(clusterizer.grouping.groups.values()):\n",
    "        datas.extend(clusterizer.fit_metrics.row_as_array(spine) for spine in group)\n",
    "        labels.extend([i for _ in group])\n",
    "    \n",
    "    labels = np.array(labels)\n",
    "    if metric is None:\n",
    "        score = silhouette_score(datas, labels, metric=clusterizer.metric)\n",
    "    else:\n",
    "        score = silhouette_score(np.array([[metric(x1, x2) for x1 in datas] for x2 in datas]), labels, metric=\"precomputed\")\n",
    "    return score\n",
    "\n",
    "def js_distance(x, y) -> float:\n",
    "    return np.sqrt(jensenshannon(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b0e25",
   "metadata": {},
   "source": [
    "## DBSCAN Classic Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c12490",
   "metadata": {},
   "source": [
    "3. Clustering using classical metrics. In `score_func` choose elbow score/silhoutte or max divergence criteria, , in `classification` — type of grouping if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_widgets import dbscan_clustering_experiment_widget\n",
    "\n",
    "min_eps = 0.2\n",
    "max_eps = 6\n",
    "eps_step = 0.1\n",
    "\n",
    "# for max divergence criteria score function and intersection data choose the type of grouping \n",
    "\n",
    "# classification = None\n",
    "# classification = labeling\n",
    "classification = manual_classification \n",
    "\n",
    "score_func = lambda clusterizer: intersection_ratios_mean_distance(classification, clusterizer.grouping, False)\n",
    "score_func = dbscan_elbow_score\n",
    "\n",
    "\n",
    "display(dbscan_clustering_experiment_widget(classic, spine_metrics, spine_dataset, score_func,\n",
    "                                            min_eps=min_eps, max_eps=max_eps, eps_step=eps_step, dim_reduction=\"pca\", show_method=show_reduction_method,\n",
    "                                            classification=classification, save_folder=classic_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87187f6d",
   "metadata": {},
   "source": [
    "4. View labeled groups or classes distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff35c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_widgets import show_class_in_space\n",
    "\n",
    "display(show_class_in_space(manual_classification, classic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768bd4a0",
   "metadata": {},
   "source": [
    "## DBSCAN Chord Histograms Euclidean Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ccdcc4",
   "metadata": {},
   "source": [
    "5. Clustering using chord distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed0dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_widgets import dbscan_clustering_experiment_widget\n",
    "\n",
    "min_eps = 0.1\n",
    "max_eps = 10\n",
    "eps_step = 0.1\n",
    "\n",
    "# for max divergence criteria score function and intersection data choose the type of grouping \n",
    "\n",
    "# classification = None\n",
    "# classification = labeling\n",
    "classification = manual_classification \n",
    "\n",
    "score_func = lambda clusterizer: intersection_ratios_mean_distance(classification, clusterizer.grouping, False)\n",
    "score_func = dbscan_elbow_score\n",
    "\n",
    "\n",
    "display(dbscan_clustering_experiment_widget(chord, spine_metrics, spine_dataset, score_func,\n",
    "                                            min_eps=min_eps, max_eps=max_eps, eps_step=eps_step, dim_reduction=\"\", show_method=show_reduction_method,\n",
    "                                            classification=classification, save_folder=chord_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572360b5",
   "metadata": {},
   "source": [
    "6. View labeled groups or classes distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8ad0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_widgets import show_class_in_space\n",
    "\n",
    "display(show_class_in_space(manual_classification, chord))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b84fa1f",
   "metadata": {},
   "source": [
    "## DBSCAN Chord Histograms Jensen — Shannon Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b15c09",
   "metadata": {},
   "source": [
    "7. Clustering using chord distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdcc5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_widgets import dbscan_clustering_experiment_widget\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "import numpy as np\n",
    "\n",
    "min_eps = 0.1\n",
    "max_eps = 1\n",
    "eps_step = 0.01\n",
    "use_pca = False\n",
    "\n",
    "# for max divergence criteria score function and intersection data choose the type of grouping \n",
    "\n",
    "# classification = None\n",
    "# classification = labeling\n",
    "classification = manual_classification \n",
    "\n",
    "score_func = lambda clusterizer: intersection_ratios_mean_distance(classification, clusterizer.grouping, False)\n",
    "score_func = dbscan_elbow_score\n",
    "\n",
    "def js_distance(x, y) -> float:\n",
    "    return np.sqrt(jensenshannon(x, y))\n",
    "\n",
    "display(dbscan_clustering_experiment_widget(chord, spine_metrics, spine_dataset, score_func, metric=js_distance,\n",
    "                                            min_eps=min_eps, max_eps=max_eps, eps_step=eps_step, dim_reduction='pca',\n",
    "                                            classification=classification, save_folder=chord_js_save_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7500fc4b",
   "metadata": {},
   "source": [
    "## View clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b22de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_widgets import inspect_saved_groupings_widget\n",
    "\n",
    "display(inspect_saved_groupings_widget(f\"{dataset_path}/clustering\", spine_dataset, spine_metrics,\n",
    "                                       chord, classic, manual_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e570e49f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
